{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#EDA"
      ],
      "metadata": {
        "id": "g7Bicy1gjbng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Question 1: Read the Bike Details dataset into a Pandas DataFrame and display its\n",
        "first 10 rows.\n",
        "- import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "\n",
        "print(\"Question 1: First 10 rows\")\n",
        "print(df.head(10))\n",
        "print(\"\\nShape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "df.head(10).to_csv(\"first_10_rows_snapshot.csv\", index=False)"
      ],
      "metadata": {
        "id": "2Cf_mIzgjeIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "\n",
        "print(\"Question 1: First 10 rows\")\n",
        "print(df.head(10))\n",
        "print(\"\\nShape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "df.head(10).to_csv(\"first_10_rows_snapshot.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "9zUdc1l-j4hE",
        "outputId": "19baedb3-50f0-4890-87ed-18555fb0e0aa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'BIKE DETAILS.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-134654912.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"figures\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATAFILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Question 1: First 10 rows\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BIKE DETAILS.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Check for missing values in all columns and describe your approach for\n",
        "handling them.\n",
        "- import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 2: Missing values check\")\n",
        "missing = df.isnull().sum()\n",
        "print(missing)\n",
        "\n",
        "# Approach (explain in report)\n",
        "# Example handling steps (we'll implement reasonable handling below):\n",
        "# - If a column has very few missing values (e.g., <1-2%), drop rows or impute using median/mode.\n",
        "# - If a numeric column: impute with median (robust to outliers).\n",
        "# - If categorical: impute with mode or 'Unknown'.\n",
        "# - If a column has too many missing values (>40-50%), consider dropping the column.\n",
        "\n",
        "# Implement a safe imputation plan (adjust thresholds as needed)\n",
        "def handle_missing(df):\n",
        "    df2 = df.copy()\n",
        "    # For numeric columns: fill with median\n",
        "    num_cols = df2.select_dtypes(include=[np.number]).columns\n",
        "    for c in num_cols:\n",
        "        if df2[c].isnull().sum() > 0:\n",
        "            df2[c] = df2[c].fillna(df2[c].median())\n",
        "    # For object/categorical: fill with mode or 'Unknown'\n",
        "    cat_cols = df2.select_dtypes(include=['object', 'category']).columns\n",
        "    for c in cat_cols:\n",
        "        if df2[c].isnull().sum() > 0:\n",
        "            try:\n",
        "                mode_val = df2[c].mode().iloc[0]\n",
        "            except Exception:\n",
        "                mode_val = \"Unknown\"\n",
        "            df2[c] = df2[c].fillna(mode_val)\n",
        "    return df2\n",
        "\n",
        "df_clean = handle_missing(df)\n",
        "print(\"\\nMissing values after imputation:\")\n",
        "print(df_clean.isnull().sum())\n"
      ],
      "metadata": {
        "id": "HfdV6Nm5lIJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 2: Missing values check\")\n",
        "missing = df.isnull().sum()\n",
        "print(missing)\n",
        "\n",
        "# Approach (explain in report)\n",
        "# Example handling steps (we'll implement reasonable handling below):\n",
        "# - If a column has very few missing values (e.g., <1-2%), drop rows or impute using median/mode.\n",
        "# - If a numeric column: impute with median (robust to outliers).\n",
        "# - If categorical: impute with mode or 'Unknown'.\n",
        "# - If a column has too many missing values (>40-50%), consider dropping the column.\n",
        "\n",
        "# Implement a safe imputation plan (adjust thresholds as needed)\n",
        "def handle_missing(df):\n",
        "    df2 = df.copy()\n",
        "    # For numeric columns: fill with median\n",
        "    num_cols = df2.select_dtypes(include=[np.number]).columns\n",
        "    for c in num_cols:\n",
        "        if df2[c].isnull().sum() > 0:\n",
        "            df2[c] = df2[c].fillna(df2[c].median())\n",
        "    # For object/categorical: fill with mode or 'Unknown'\n",
        "    cat_cols = df2.select_dtypes(include=['object', 'category']).columns\n",
        "    for c in cat_cols:\n",
        "        if df2[c].isnull().sum() > 0:\n",
        "            try:\n",
        "                mode_val = df2[c].mode().iloc[0]\n",
        "            except Exception:\n",
        "                mode_val = \"Unknown\"\n",
        "            df2[c] = df2[c].fillna(mode_val)\n",
        "    return df2\n",
        "\n",
        "df_clean = handle_missing(df)\n",
        "print(\"\\nMissing values after imputation:\")\n",
        "print(df_clean.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "6188e531-fc47-4874-9500-c558b0a90776",
        "id": "m93edV_ZmKru"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'BIKE DETAILS.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3735957296.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"figures\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATAFILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nQuestion 2: Missing values check\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'BIKE DETAILS.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: Plot the distribution of selling prices using a histogram and describe the\n",
        "overall trend.\n",
        "- import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 3: Distribution of selling_price\")\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(df_clean['selling_price'], bins=30, kde=True)\n",
        "plt.title(\"Distribution of selling_price\")\n",
        "plt.xlabel(\"selling_price\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figures/hist_selling_price.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DUinOJAjmT78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 3: Distribution of selling_price\")\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(df_clean['selling_price'], bins=30, kde=True)\n",
        "plt.title(\"Distribution of selling_price\")\n",
        "plt.xlabel(\"selling_price\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figures/hist_selling_price.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OQeEyUuDmZPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Create a bar plot to visualize the average selling price for each seller_type\n",
        "and write one observation.\n",
        "- import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 4: Average selling price by seller_type\")\n",
        "if 'seller_type' in df_clean.columns:\n",
        "    avg_by_seller = df_clean.groupby('seller_type')['selling_price'].mean().sort_values(ascending=False)\n",
        "    print(avg_by_seller)\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.barplot(x=avg_by_seller.index, y=avg_by_seller.values)\n",
        "    plt.xlabel(\"seller_type\")\n",
        "    plt.ylabel(\"Average selling_price\")\n",
        "    plt.title(\"Average selling_price by seller_type\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"figures/bar_avg_selling_by_seller_type.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Column 'seller_type' not found.\")\n",
        "\n",
        "# One observation (example):\n",
        "# \"Observation: seller_type X has higher average selling price than seller_type Y — suggests ...\"\n"
      ],
      "metadata": {
        "id": "xy6YXJ8VmmTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 4: Average selling price by seller_type\")\n",
        "if 'seller_type' in df_clean.columns:\n",
        "    avg_by_seller = df_clean.groupby('seller_type')['selling_price'].mean().sort_values(ascending=False)\n",
        "    print(avg_by_seller)\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.barplot(x=avg_by_seller.index, y=avg_by_seller.values)\n",
        "    plt.xlabel(\"seller_type\")\n",
        "    plt.ylabel(\"Average selling_price\")\n",
        "    plt.title(\"Average selling_price by seller_type\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"figures/bar_avg_selling_by_seller_type.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Column 'seller_type' not found.\")\n",
        "\n",
        "# One observation (example):\n",
        "# \"Observation: seller_type X has higher average selling price than seller_type Y — suggests ...\"\n"
      ],
      "metadata": {
        "id": "x4iSpieXmuK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Compute the average km_driven for each ownership type (1st owner,\n",
        "2nd owner, etc.), and present the result as a bar plot.\n",
        "- import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 5: Average km_driven by owner\")\n",
        "if 'owner' in df_clean.columns and 'km_driven' in df_clean.columns:\n",
        "    avg_km_by_owner = df_clean.groupby('owner')['km_driven'].mean().sort_values(ascending=False)\n",
        "    print(avg_km_by_owner)\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.barplot(x=avg_km_by_owner.index, y=avg_km_by_owner.values)\n",
        "    plt.xlabel(\"owner\")\n",
        "    plt.ylabel(\"Average km_driven\")\n",
        "    plt.title(\"Average km_driven by ownership type\")\n",
        "    plt.xticks(rotation=30)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"figures/bar_avg_km_by_owner.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Columns 'owner' or 'km_driven' not found.\")"
      ],
      "metadata": {
        "id": "Gxn_Z0jgm27h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 5: Average km_driven by owner\")\n",
        "if 'owner' in df_clean.columns and 'km_driven' in df_clean.columns:\n",
        "    avg_km_by_owner = df_clean.groupby('owner')['km_driven'].mean().sort_values(ascending=False)\n",
        "    print(avg_km_by_owner)\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.barplot(x=avg_km_by_owner.index, y=avg_km_by_owner.values)\n",
        "    plt.xlabel(\"owner\")\n",
        "    plt.ylabel(\"Average km_driven\")\n",
        "    plt.title(\"Average km_driven by ownership type\")\n",
        "    plt.xticks(rotation=30)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"figures/bar_avg_km_by_owner.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Columns 'owner' or 'km_driven' not found.\")"
      ],
      "metadata": {
        "id": "4qWRs9KBm8JW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Use the IQR method to detect and remove outliers from the km_driven\n",
        "column. Show before-and-after summary statistics.\n",
        "- import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 6: IQR based outlier removal on km_driven\")\n",
        "if 'km_driven' in df_clean.columns:\n",
        "    desc_before = df_clean['km_driven'].describe()\n",
        "    print(\"Before removal:\\n\", desc_before)\n",
        "    Q1 = df_clean['km_driven'].quantile(0.25)\n",
        "    Q3 = df_clean['km_driven'].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    print(\"IQR:\", IQR, \"Lower bound:\", lower, \"Upper bound:\", upper)\n",
        "\n",
        "    df_no_out = df_clean[(df_clean['km_driven'] >= lower) & (df_clean['km_driven'] <= upper)].copy()\n",
        "    desc_after = df_no_out['km_driven'].describe()\n",
        "    print(\"After removal:\\n\", desc_after)\n",
        "\n",
        "    # Show counts removed\n",
        "    removed_count = df_clean.shape[0] - df_no_out.shape[0]\n",
        "    print(f\"Removed {removed_count} rows as km_driven outliers.\")\n",
        "else:\n",
        "    print(\"Column 'km_driven' not found.\")"
      ],
      "metadata": {
        "id": "ENPPSza5nNRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 6: IQR based outlier removal on km_driven\")\n",
        "if 'km_driven' in df_clean.columns:\n",
        "    desc_before = df_clean['km_driven'].describe()\n",
        "    print(\"Before removal:\\n\", desc_before)\n",
        "    Q1 = df_clean['km_driven'].quantile(0.25)\n",
        "    Q3 = df_clean['km_driven'].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    print(\"IQR:\", IQR, \"Lower bound:\", lower, \"Upper bound:\", upper)\n",
        "\n",
        "    df_no_out = df_clean[(df_clean['km_driven'] >= lower) & (df_clean['km_driven'] <= upper)].copy()\n",
        "    desc_after = df_no_out['km_driven'].describe()\n",
        "    print(\"After removal:\\n\", desc_after)\n",
        "\n",
        "    # Show counts removed\n",
        "    removed_count = df_clean.shape[0] - df_no_out.shape[0]\n",
        "    print(f\"Removed {removed_count} rows as km_driven outliers.\")\n",
        "else:\n",
        "    print(\"Column 'km_driven' not found.\")"
      ],
      "metadata": {
        "id": "T816oFMhnTD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Create a scatter plot of year vs. selling_price to explore the\n",
        "relationship between a bike's age and its price.\n",
        "- import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 7: Scatter plot year vs selling_price\")\n",
        "if 'year' in df_clean.columns and 'selling_price' in df_clean.columns:\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.scatterplot(x='year', y='selling_price', data=df_clean, alpha=0.6)\n",
        "    plt.xlabel(\"year\")\n",
        "    plt.ylabel(\"selling_price\")\n",
        "    plt.title(\"Year vs Selling Price\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"figures/scatter_year_vs_price.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Columns 'year' or 'selling_price' not found.\")"
      ],
      "metadata": {
        "id": "aAJ1_ol4nj5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 7: Scatter plot year vs selling_price\")\n",
        "if 'year' in df_clean.columns and 'selling_price' in df_clean.columns:\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.scatterplot(x='year', y='selling_price', data=df_clean, alpha=0.6)\n",
        "    plt.xlabel(\"year\")\n",
        "    plt.ylabel(\"selling_price\")\n",
        "    plt.title(\"Year vs Selling Price\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"figures/scatter_year_vs_price.png\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Columns 'year' or 'selling_price' not found.\")"
      ],
      "metadata": {
        "id": "rIN2FlyZoBAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Convert the seller_type column into numeric format using one-hot\n",
        "encoding. Display the first 5 rows of the resulting DataFrame.\n",
        "- import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 8: One-hot encode seller_type\")\n",
        "if 'seller_type' in df_clean.columns:\n",
        "    df_ohe = pd.get_dummies(df_clean, columns=['seller_type'], drop_first=False)\n",
        "    print(\"First 5 rows after one-hot encoding seller_type:\")\n",
        "    print(df_ohe.head(5))\n",
        "    df_ohe.head(5).to_csv(\"first5_ohe_seller_type.csv\", index=False)\n",
        "else:\n",
        "    print(\"Column 'seller_type' not found.\")"
      ],
      "metadata": {
        "id": "LrmmQbnmoMi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 8: One-hot encode seller_type\")\n",
        "if 'seller_type' in df_clean.columns:\n",
        "    df_ohe = pd.get_dummies(df_clean, columns=['seller_type'], drop_first=False)\n",
        "    print(\"First 5 rows after one-hot encoding seller_type:\")\n",
        "    print(df_ohe.head(5))\n",
        "    df_ohe.head(5).to_csv(\"first5_ohe_seller_type.csv\", index=False)\n",
        "else:\n",
        "    print(\"Column 'seller_type' not found.\")"
      ],
      "metadata": {
        "id": "6SNalJQPoVOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Generate a heatmap of the correlation matrix for all numeric columns.\n",
        "What correlations stand out the most?\n",
        "- import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 9: Correlation heatmap for numeric columns\")\n",
        "num_df = df_clean.select_dtypes(include=[np.number])\n",
        "corr = num_df.corr()\n",
        "print(\"Correlation matrix:\\n\", corr)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
        "plt.title(\"Correlation matrix (numeric columns)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figures/heatmap_correlations.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2yA2tvnjolZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 9: Correlation heatmap for numeric columns\")\n",
        "num_df = df_clean.select_dtypes(include=[np.number])\n",
        "corr = num_df.corr()\n",
        "print(\"Correlation matrix:\\n\", corr)\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
        "plt.title(\"Correlation matrix (numeric columns)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"figures/heatmap_correlations.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Uma1LO9yotDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Summarize your findings in a brief report:\n",
        "● What are the most important factors affecting a bike's selling price?\n",
        "● Mention any data cleaning or feature engineering you performed.\n",
        "\n",
        "- import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 10: Summary of findings\")\n",
        "# Compose a short report text to be included in the PDF\n",
        "report_lines = []\n",
        "report_lines.append(\"Summary of Findings:\")\n",
        "# We'll compute some metrics to support the statements\n",
        "# Example important factors based on correlations:\n",
        "if 'selling_price' in num_df.columns:\n",
        "    corr_with_price = corr['selling_price'].drop('selling_price').sort_values(ascending=False)\n",
        "    report_lines.append(\"Top correlations with selling_price:\\n\" + corr_with_price.to_string())\n",
        "else:\n",
        "    report_lines.append(\"selling_price not numeric / not found in numeric columns.\")\n",
        "\n",
        "report_lines.append(\"\\nData cleaning and feature engineering performed:\")\n",
        "report_lines.append(\"- Missing values imputed: numeric->median, categorical->mode.\")\n",
        "report_lines.append(\"- Outliers in km_driven detected & removed using IQR method (1.5*IQR).\")\n",
        "report_lines.append(\"- One-hot encoding applied to seller_type.\")\n",
        "\n",
        "report_text = \"\\n\".join(report_lines)\n",
        "print(report_text)\n",
        "\n",
        "# Save the report text to a file\n",
        "with open(\"EDA_summary_report.txt\", \"w\") as f:\n",
        "    f.write(report_text)\n",
        "\n",
        "# OPTIONAL: If you want a single PDF with images and answers, you can use a library like reportlab, FPDF or convert a Jupyter notebook to PDF.\n",
        "# Example (if in notebook):\n",
        "#   !jupyter nbconvert --to pdf EDA_assignment_solution.ipynb\n",
        "#\n",
        "# Or assemble a simple PDF using matplotlib.backends.backend_pdf.PdfPages:\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "with PdfPages(\"EDA_assignment_results.pdf\") as pdf:\n",
        "    # Add a small text page (report)\n",
        "    plt.figure(figsize=(8.27, 11.69))  # A4 portrait\n",
        "    plt.axis('off')\n",
        "    plt.text(0, 1, \"EDA Assignment Results\", fontsize=18, weight='bold')\n",
        "    plt.text(0, 0.95, report_text, fontsize=8, va='top')\n",
        "    pdf.savefig()\n",
        "    plt.close()\n",
        "\n",
        "    # Add each saved figure to PDF\n",
        "    fig_files = sorted([f for f in os.listdir(\"figures\") if f.endswith(\".png\")])\n",
        "    for fpath in fig_files:\n",
        "        im = plt.imread(os.path.join(\"figures\", fpath))\n",
        "        plt.figure(figsize=(8.27, 11.69))\n",
        "        plt.imshow(im)\n",
        "        plt.axis('off')\n",
        "        pdf.savefig()\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "Cgq8RW8_ozbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "DATAFILE = \"BIKE DETAILS.csv\"\n",
        "os.makedirs(\"figures\", exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(DATAFILE)\n",
        "print(\"\\nQuestion 10: Summary of findings\")\n",
        "# Compose a short report text to be included in the PDF\n",
        "report_lines = []\n",
        "report_lines.append(\"Summary of Findings:\")\n",
        "# We'll compute some metrics to support the statements\n",
        "# Example important factors based on correlations:\n",
        "if 'selling_price' in num_df.columns:\n",
        "    corr_with_price = corr['selling_price'].drop('selling_price').sort_values(ascending=False)\n",
        "    report_lines.append(\"Top correlations with selling_price:\\n\" + corr_with_price.to_string())\n",
        "else:\n",
        "    report_lines.append(\"selling_price not numeric / not found in numeric columns.\")\n",
        "\n",
        "report_lines.append(\"\\nData cleaning and feature engineering performed:\")\n",
        "report_lines.append(\"- Missing values imputed: numeric->median, categorical->mode.\")\n",
        "report_lines.append(\"- Outliers in km_driven detected & removed using IQR method (1.5*IQR).\")\n",
        "report_lines.append(\"- One-hot encoding applied to seller_type.\")\n",
        "\n",
        "report_text = \"\\n\".join(report_lines)\n",
        "print(report_text)\n",
        "\n",
        "# Save the report text to a file\n",
        "with open(\"EDA_summary_report.txt\", \"w\") as f:\n",
        "    f.write(report_text)\n",
        "\n",
        "# OPTIONAL: If you want a single PDF with images and answers, you can use a library like reportlab, FPDF or convert a Jupyter notebook to PDF.\n",
        "# Example (if in notebook):\n",
        "#   !jupyter nbconvert --to pdf EDA_assignment_solution.ipynb\n",
        "#\n",
        "# Or assemble a simple PDF using matplotlib.backends.backend_pdf.PdfPages:\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "with PdfPages(\"EDA_assignment_results.pdf\") as pdf:\n",
        "    # Add a small text page (report)\n",
        "    plt.figure(figsize=(8.27, 11.69))  # A4 portrait\n",
        "    plt.axis('off')\n",
        "    plt.text(0, 1, \"EDA Assignment Results\", fontsize=18, weight='bold')\n",
        "    plt.text(0, 0.95, report_text, fontsize=8, va='top')\n",
        "    pdf.savefig()\n",
        "    plt.close()\n",
        "\n",
        "    # Add each saved figure to PDF\n",
        "    fig_files = sorted([f for f in os.listdir(\"figures\") if f.endswith(\".png\")])\n",
        "    for fpath in fig_files:\n",
        "        im = plt.imread(os.path.join(\"figures\", fpath))\n",
        "        plt.figure(figsize=(8.27, 11.69))\n",
        "        plt.imshow(im)\n",
        "        plt.axis('off')\n",
        "        pdf.savefig()\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "9akzNNiVo3-O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}